% Ensure that arXiv processes this as PDF.
\pdfoutput=1

\documentclass{book}
\usepackage{natbib}
\usepackage{comment}
\bibliographystyle{abbrvnat}
\input{packages}
\input{macros}

\usepackage{amsthm,fixfoot}

\usepackage{listings}
\input{lstsetup}

\input{aosd13/customMacros}
\input{pldi14/customMacros}

\input{pldi14/macros_part2}
% from pldi14
\newcommand{\ILC}{ILC}
% from aosd13
\usepackage{comment}
\excludecomment{extraEval}
\includecomment{techrep}
\excludecomment{nontechrep}
\excludecomment{todos}
\includecomment{forNonBeamer}

\title{PhD Thesis}
\author{Paolo G. Giarrusso}
\begin{document}
\maketitle
\section*{Abstract}
% Programs manipulating data collections require

% \begin{abstract}
% \end{abstract}
\chapter{Intro}

A program manipulating collections of data will often query those collections.
For instance, a program manipulating anagraphic data about German citizens might
need to compute their average age or other anagraphic information. These
collections can be big, so query execution can be expensive and warrant
considerable optimization effort. Moreover, when input data changes, we often
want to obtain the results of a query for the new input without rerunning that
query from scratch.

% \section{}
Efficient queries are classically written either as declarative database queries that are
optimized by database optimizers, or as manually optimized code using
collection libraries. Compare maintaining anagraphic data for a population
as either a relational database or a collection:
\begin{itemize}
\item If the population data is maintained by a database management system
  (DBMS), a programmer that needs to look up quickly people by age, can just add
  an index and keep the lookup query unchanged. When the data is updated, the
  DBMS can adapt the index to the new changes, that is, it can \emph{incrementally} update the
  index automatically.
  Maintaining indexes adds possible to
  One can then experiment with different sets of indexes and workloads
\item If the population data is maintained as an in-memory collection, adding an
  index requires modifying by hand queries to reuse it for maximum performance.
  Experimenting and ensuring all changes to population data update the index to
  maintain correctness. This is error-prone, and while there is a considerable
  amount of research on this problem\pg{cite}, incorrect update code is common.
\end{itemize}
Modern libraries offer high-level APIs for manipulating (in-memory) collections;
equivalently, such an API is an embedded domain-specific language (EDSL).

Compared to SQL, EDSL queries will typically be able to use user-defined
functions in queries. Moreover, the author of EDSL queries can enjoy abstraction
mechanisms from the underlying language.

\pg{Examples!}

Collection operations are typically executed directly; however, they can instead
construct a query representation that can then be optimized.

To optimize queries we can transfer techniques known from both databases and
programming languages. Incrementalizing arbitrary queries, however, is a much
harder problem in general.

\section{Our design for incrementalizing queries}
We designed our incrementalization system by abstracting from needs and ideas for
collection APIs.
\begin{itemize}
\item collection APIs are typically higher-order. This allows further
  flexibility compared to first-order query languages: in particular we can
  design new operators in terms of existing ones.
\item many collection types support equations that can be used for optimization.
  For instance
\end{itemize}

\subsection{Domain-specific}
Special optimizations are possible because many collection datatypes, equality
is not purely structural. Two lists are equal if they are structurally equal.
But two sets are equal if they have the same elements, which does not imply they
are structurally equal.\footnote{\pg{Cool but not necessarily appropriate here.}
  Technically, the datatypes are not freely generated and their signatures
  contain further equations.}
%
A general-purpose optimizer cannot exploit this to return a structurally
different set with ``the same meaning'', but a domain-specific optimizer can be
instructed to do so.

Taking this into account we were led to design our incrementalization system to
allow domain-specific support from the start.

\chapter{Reifying collection queries}

\input{aosd13/graphs/evalResLos}
\input{aosd13/paperBody}
\input{aosd13/aosd13-extended-appendixes}

\newcommand{\co}[1]{\code{#1}} %Adaptation between different interfaces
\chapter{Incrementalizing simply-typed \TitleLambda{}-calculus}
\input{pldi14/agda}

\input{pldi14/sec-intro}
\input{pldi14/sec-change-theory}
\input{pldi14/sec-differentiate}
\input{pldi14/sec-practice}
\input{pldi14/sec-rw}
\input{pldi14/sec-concl}

% Appendixes
\input{pldi14/sec-evaluation}
\input{pldi14/sec-addendum}

\input{pldi14/sec-formal}

\input{pldi14/sec-change-structures}

\begin{oldSec}
\input{pldi14/sec-STLC-correct}
\end{oldSec}

\begin{oldSec}
\input{pldi14/sec-informal}
\end{oldSec}


\pg{Plan for things that complete the original paper's story: add them by
  revising that text and in that chapter.}

\bibliography{Bibs/DB,Bibs/ProgLang,Bibs/SoftEng,Bibs/own}
\end{document}
%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
