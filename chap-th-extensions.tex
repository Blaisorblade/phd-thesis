% Emacs, this is -*- latex -*-!
%% ODER: format ==         = "\mathrel{==}"
%% ODER: format /=         = "\neq "
%
%
\makeatletter
\@ifundefined{lhs2tex.lhs2tex.sty.read}%
  {\@namedef{lhs2tex.lhs2tex.sty.read}{}%
   \newcommand\SkipToFmtEnd{}%
   \newcommand\EndFmtInput{}%
   \long\def\SkipToFmtEnd#1\EndFmtInput{}%
  }\SkipToFmtEnd

\newcommand\ReadOnlyOnce[1]{\@ifundefined{#1}{\@namedef{#1}{}}\SkipToFmtEnd}
\usepackage{amstext}
\usepackage{amssymb}
\usepackage{stmaryrd}
\DeclareFontFamily{OT1}{cmtex}{}
\DeclareFontShape{OT1}{cmtex}{m}{n}
  {<5><6><7><8>cmtex8
   <9>cmtex9
   <10><10.95><12><14.4><17.28><20.74><24.88>cmtex10}{}
\DeclareFontShape{OT1}{cmtex}{m}{it}
  {<-> ssub * cmtt/m/it}{}
\newcommand{\texfamily}{\fontfamily{cmtex}\selectfont}
\DeclareFontShape{OT1}{cmtt}{bx}{n}
  {<5><6><7><8>cmtt8
   <9>cmbtt9
   <10><10.95><12><14.4><17.28><20.74><24.88>cmbtt10}{}
\DeclareFontShape{OT1}{cmtex}{bx}{n}
  {<-> ssub * cmtt/bx/n}{}
\newcommand{\tex}[1]{\text{\texfamily#1}}	% NEU

\newcommand{\Sp}{\hskip.33334em\relax}


\newcommand{\Conid}[1]{\mathit{#1}}
\newcommand{\Varid}[1]{\mathit{#1}}
\newcommand{\anonymous}{\kern0.06em \vbox{\hrule\@width.5em}}
\newcommand{\plus}{\mathbin{+\!\!\!+}}
\newcommand{\bind}{\mathbin{>\!\!\!>\mkern-6.7mu=}}
\newcommand{\rbind}{\mathbin{=\mkern-6.7mu<\!\!\!<}}% suggested by Neil Mitchell
\newcommand{\sequ}{\mathbin{>\!\!\!>}}
\renewcommand{\leq}{\leqslant}
\renewcommand{\geq}{\geqslant}
\usepackage{polytable}

%mathindent has to be defined
\@ifundefined{mathindent}%
  {\newdimen\mathindent\mathindent\leftmargini}%
  {}%

\def\resethooks{%
  \global\let\SaveRestoreHook\empty
  \global\let\ColumnHook\empty}
\newcommand*{\savecolumns}[1][default]%
  {\g@addto@macro\SaveRestoreHook{\savecolumns[#1]}}
\newcommand*{\restorecolumns}[1][default]%
  {\g@addto@macro\SaveRestoreHook{\restorecolumns[#1]}}
\newcommand*{\aligncolumn}[2]%
  {\g@addto@macro\ColumnHook{\column{#1}{#2}}}

\resethooks

\newcommand{\onelinecommentchars}{\quad-{}- }
\newcommand{\commentbeginchars}{\enskip\{-}
\newcommand{\commentendchars}{-\}\enskip}

\newcommand{\visiblecomments}{%
  \let\onelinecomment=\onelinecommentchars
  \let\commentbegin=\commentbeginchars
  \let\commentend=\commentendchars}

\newcommand{\invisiblecomments}{%
  \let\onelinecomment=\empty
  \let\commentbegin=\empty
  \let\commentend=\empty}

\visiblecomments

\newlength{\blanklineskip}
\setlength{\blanklineskip}{0.66084ex}

\newcommand{\hsindent}[1]{\quad}% default is fixed indentation
\let\hspre\empty
\let\hspost\empty
\newcommand{\NB}{\textbf{NB}}
\newcommand{\Todo}[1]{$\langle$\textbf{To do:}~#1$\rangle$}

\EndFmtInput
\makeatother
%
%
%
%
%
%
% This package provides two environments suitable to take the place
% of hscode, called "plainhscode" and "arrayhscode". 
%
% The plain environment surrounds each code block by vertical space,
% and it uses \abovedisplayskip and \belowdisplayskip to get spacing
% similar to formulas. Note that if these dimensions are changed,
% the spacing around displayed math formulas changes as well.
% All code is indented using \leftskip.
%
% Changed 19.08.2004 to reflect changes in colorcode. Should work with
% CodeGroup.sty.
%
\ReadOnlyOnce{polycode.fmt}%
\makeatletter

\newcommand{\hsnewpar}[1]%
  {{\parskip=0pt\parindent=0pt\par\vskip #1\noindent}}

% can be used, for instance, to redefine the code size, by setting the
% command to \small or something alike
\newcommand{\hscodestyle}{}

% The command \sethscode can be used to switch the code formatting
% behaviour by mapping the hscode environment in the subst directive
% to a new LaTeX environment.

\newcommand{\sethscode}[1]%
  {\expandafter\let\expandafter\hscode\csname #1\endcsname
   \expandafter\let\expandafter\endhscode\csname end#1\endcsname}

% "compatibility" mode restores the non-polycode.fmt layout.

\newenvironment{compathscode}%
  {\par\noindent
   \advance\leftskip\mathindent
   \hscodestyle
   \let\\=\@normalcr
   \let\hspre\(\let\hspost\)%
   \pboxed}%
  {\endpboxed\)%
   \par\noindent
   \ignorespacesafterend}

\newcommand{\compaths}{\sethscode{compathscode}}

% "plain" mode is the proposed default.
% It should now work with \centering.
% This required some changes. The old version
% is still available for reference as oldplainhscode.

\newenvironment{plainhscode}%
  {\hsnewpar\abovedisplayskip
   \advance\leftskip\mathindent
   \hscodestyle
   \let\hspre\(\let\hspost\)%
   \pboxed}%
  {\endpboxed%
   \hsnewpar\belowdisplayskip
   \ignorespacesafterend}

\newenvironment{oldplainhscode}%
  {\hsnewpar\abovedisplayskip
   \advance\leftskip\mathindent
   \hscodestyle
   \let\\=\@normalcr
   \(\pboxed}%
  {\endpboxed\)%
   \hsnewpar\belowdisplayskip
   \ignorespacesafterend}

% Here, we make plainhscode the default environment.

\newcommand{\plainhs}{\sethscode{plainhscode}}
\newcommand{\oldplainhs}{\sethscode{oldplainhscode}}
\plainhs

% The arrayhscode is like plain, but makes use of polytable's
% parray environment which disallows page breaks in code blocks.

\newenvironment{arrayhscode}%
  {\hsnewpar\abovedisplayskip
   \advance\leftskip\mathindent
   \hscodestyle
   \let\\=\@normalcr
   \(\parray}%
  {\endparray\)%
   \hsnewpar\belowdisplayskip
   \ignorespacesafterend}

\newcommand{\arrayhs}{\sethscode{arrayhscode}}

% The mathhscode environment also makes use of polytable's parray 
% environment. It is supposed to be used only inside math mode 
% (I used it to typeset the type rules in my thesis).

\newenvironment{mathhscode}%
  {\parray}{\endparray}

\newcommand{\mathhs}{\sethscode{mathhscode}}

% texths is similar to mathhs, but works in text mode.

\newenvironment{texthscode}%
  {\(\parray}{\endparray\)}

\newcommand{\texths}{\sethscode{texthscode}}

% The framed environment places code in a framed box.

\def\codeframewidth{\arrayrulewidth}
\RequirePackage{calc}

\newenvironment{framedhscode}%
  {\parskip=\abovedisplayskip\par\noindent
   \hscodestyle
   \arrayrulewidth=\codeframewidth
   \tabular{@{}|p{\linewidth-2\arraycolsep-2\arrayrulewidth-2pt}|@{}}%
   \hline\framedhslinecorrect\\{-1.5ex}%
   \let\endoflinesave=\\
   \let\\=\@normalcr
   \(\pboxed}%
  {\endpboxed\)%
   \framedhslinecorrect\endoflinesave{.5ex}\hline
   \endtabular
   \parskip=\belowdisplayskip\par\noindent
   \ignorespacesafterend}

\newcommand{\framedhslinecorrect}[2]%
  {#1[#2]}

\newcommand{\framedhs}{\sethscode{framedhscode}}

% The inlinehscode environment is an experimental environment
% that can be used to typeset displayed code inline.

\newenvironment{inlinehscode}%
  {\(\def\column##1##2{}%
   \let\>\undefined\let\<\undefined\let\\\undefined
   \newcommand\>[1][]{}\newcommand\<[1][]{}\newcommand\\[1][]{}%
   \def\fromto##1##2##3{##3}%
   \def\nextline{}}{\) }%

\newcommand{\inlinehs}{\sethscode{inlinehscode}}

% The joincode environment is a separate environment that
% can be used to surround and thereby connect multiple code
% blocks.

\newenvironment{joincode}%
  {\let\orighscode=\hscode
   \let\origendhscode=\endhscode
   \def\endhscode{\def\hscode{\endgroup\def\@currenvir{hscode}\\}\begingroup}
   %\let\SaveRestoreHook=\empty
   %\let\ColumnHook=\empty
   %\let\resethooks=\empty
   \orighscode\def\hscode{\endgroup\def\@currenvir{hscode}}}%
  {\origendhscode
   \global\let\hscode=\orighscode
   \global\let\endhscode=\origendhscode}%

\makeatother
\EndFmtInput
%
%
%
% First, let's redefine the forall, and the dot.
%
%
% This is made in such a way that after a forall, the next
% dot will be printed as a period, otherwise the formatting
% of `comp_` is used. By redefining `comp_`, as suitable
% composition operator can be chosen. Similarly, period_
% is used for the period.
%
\ReadOnlyOnce{forall.fmt}%
\makeatletter

% The HaskellResetHook is a list to which things can
% be added that reset the Haskell state to the beginning.
% This is to recover from states where the hacked intelligence
% is not sufficient.

\let\HaskellResetHook\empty
\newcommand*{\AtHaskellReset}[1]{%
  \g@addto@macro\HaskellResetHook{#1}}
\newcommand*{\HaskellReset}{\HaskellResetHook}

\global\let\hsforallread\empty

\newcommand\hsforall{\global\let\hsdot=\hsperiodonce}
\newcommand*\hsperiodonce[2]{#2\global\let\hsdot=\hscompose}
\newcommand*\hscompose[2]{#1}

\AtHaskellReset{\global\let\hsdot=\hscompose}

% In the beginning, we should reset Haskell once.
\HaskellReset

\makeatother
\EndFmtInput


% https://github.com/conal/talk-2015-essence-and-origins-of-frp/blob/master/mine.fmt
% Complexity notation:






% If an argument to a formatting directive starts with let, lhs2TeX likes to
% helpfully prepend a space to the let, even though that's seldom desirable.
% Write lett to prevent that.













































% Hook into forall.fmt:
% Add proper spacing after forall-generated dots.











% We shouldn't use /=, that means not equal (even if it can be overriden)!







% XXX



%  format `stoup` = "\blackdiamond"






% Cancel the effect of \; (that is \thickspace)



% Use as in |vapply vf va (downto n) v|.
% (downto n) is parsed as an application argument, so we must undo the produced
% spacing.

% indexed big-step eval
% without environments
% big-step eval
% change big-step eval








% \, is 3mu, \! is -3mu, so this is almost \!\!.


\def\deriveDefCore{%
\begin{align*}
  \ensuremath{\Derive{\lambda (\Varid{x}\typcolon\sigma)\to \Varid{t}}} &= \ensuremath{\lambda (\Varid{x}\typcolon\sigma)\;(\Varid{dx}\typcolon\Delta \sigma)\to \Derive{\Varid{t}}} \\
  \ensuremath{\Derive{\Varid{s}\;\Varid{t}}} &= \ensuremath{\Derive{\Varid{s}}\;\Varid{t}\;\Derive{\Varid{t}}} \\
  \ensuremath{\Derive{\Varid{x}}} &= \ensuremath{\Varid{dx}} \\
  \ensuremath{\Derive{\Varid{c}}} &= \ensuremath{\DeriveConst{\Varid{c}}}
\end{align*}
}


% Drop unsightly numbers from function names. The ones at the end could be
% formatted as subscripts, but not the ones in the middle.


\chapter{Extensions and theoretical discussion}
\label{ch:misc-extensions}
In this \lcnamecref{ch:misc-extensions} we collect discussion of a few
additional topics related to ILC that do not suffice for standalone chapters.
We
show how to differentiation general recursion~\cref{sec:general-recursion}, we
exhibit a function change that is not valid for any function
(\cref{sec:very-invalid}), we contrast our representation of function changes
with \emph{pointwise} function changes (\cref{ssec:pointwise-changes}), and we
compare our formalization with the one presented in \citep{CaiEtAl2014ILC}
(\cref{sec:alt-change-validity}).

\section{General recursion}
\label{sec:general-recursion}
This section discusses informally how to differentiate terms
using general recursion and what is the behavior of the resulting terms.

\subsection{Differentiating general recursion}

Earlier we gave a rule for differentiating (non-recursive) \ensuremath{\mathbf{let}}:
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{29}{@{}>{\hspre}c<{\hspost}@{}}%
\column{29E}{@{}l@{}}%
\column{32}{@{}>{\hspre}l<{\hspost}@{}}%
\column{38}{@{}>{\hspre}l<{\hspost}@{}}%
\column{42}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[B]{}\Derive{\mathbf{let}\;\Varid{x}\mathrel{=}\Varid{t}_{1}\;\mathbf{in}\;\Varid{t}_{2}}{}\<[29]%
\>[29]{}\mathrel{=}{}\<[29E]%
\>[32]{}\mathbf{let}\;{}\<[38]%
\>[38]{}\Varid{x}{}\<[42]%
\>[42]{}\mathrel{=}\Varid{t}_{1}{}\<[E]%
\\
\>[38]{}\Varid{dx}{}\<[42]%
\>[42]{}\mathrel{=}\Derive{\Varid{t}_{1}}{}\<[E]%
\\
\>[32]{}\mathbf{in}\;{}\<[38]%
\>[38]{}\Derive{\Varid{t}_{2}}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
% derive(lett x = t1 in t2) =
%   lett  x = t1
%         dx = derive(t1)
%   in    derive(t2)
It turns out that we can use the same rule also for recursive
\ensuremath{\mathbf{let}}-bindings, which we write here (and only here) \ensuremath{\mathbf{letrec}} for emphasis:
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{31}{@{}>{\hspre}c<{\hspost}@{}}%
\column{31E}{@{}l@{}}%
\column{34}{@{}>{\hspre}l<{\hspost}@{}}%
\column{42}{@{}>{\hspre}l<{\hspost}@{}}%
\column{46}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[B]{}\Derive{\mathbf{letrec}\;\Varid{x}\mathrel{=}\Varid{t}_{1}\;\mathbf{in}\;\Varid{t}_{2}}{}\<[31]%
\>[31]{}\mathrel{=}{}\<[31E]%
\>[34]{}\mathbf{letrec}\;{}\<[42]%
\>[42]{}\Varid{x}{}\<[46]%
\>[46]{}\mathrel{=}\Varid{t}_{1}{}\<[E]%
\\
\>[42]{}\Varid{dx}{}\<[46]%
\>[46]{}\mathrel{=}\Derive{\Varid{t}_{1}}{}\<[E]%
\\
\>[34]{}\mathbf{in}\;{}\<[42]%
\>[42]{}\Derive{\Varid{t}_{2}}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
This rule applies also to recursive top-level definitions, since in our scenario
they can be understood as uses of \ensuremath{\mathbf{letrec}}.
% derive(letrec x = t1 in t2) =
%   letrec  x = t1
%           dx = derive(t1)
%   in      derive(t2)

\pg{Far from perfect. Better reorganize. This order makes little sense.}
\begin{example}
  In \cref{ex:syn-changes-map} we presented a derivative \ensuremath{\Varid{dmap}} for
  \ensuremath{\Varid{map}}; since we wrote \ensuremath{\Varid{dmap}} by hand, we had to prove that \ensuremath{\Varid{dmap}} is a
  derivative for \ensuremath{\Varid{map}}.

  We can instead obtain \ensuremath{\Varid{dmap}} by deriving \ensuremath{\Varid{map}} with our new rule for recursive
  functions:\footnote{The handling of invalid changes is however still ad-hoc;
    we can use the generic support for sum types, obtain additional equations
    for cases where the list length changes, and then remove them, with the
    informal justification that we declared such changes illegal.}
% \begin{code}
% map f = fix go
%   where
%     go self Nil = Nil
%     go self (Cons x xs) = Cons (f x) (self xs)
% \end{code}

% Applying the derivation rules, we get that
% |dmap f df = fix ((derive go) (fix go))|,
% and since |fix go = map f| we can write:
% \begin{code}
% dmap f df = fix (dgo (map f))
%   where
%     dgo self dself Nil Nil = Nil
%     dgo self dself (Cons x xs) (Cons dx dxs) =
%       Cons (df x dx) (dself xs dxs)
% \end{code}
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[B]{}\Varid{dmap}\;\Varid{f}\;\Varid{df}\;\Conid{Nil}\;\Conid{Nil}\mathrel{=}\Conid{Nil}{}\<[E]%
\\
\>[B]{}\Varid{dmap}\;\Varid{f}\;\Varid{df}\;(\Conid{Cons}\;\Varid{x}\;\Varid{xs})\;(\Conid{Cons}\;\Varid{dx}\;\Varid{dxs})\mathrel{=}{}\<[E]%
\\
\>[B]{}\hsindent{3}{}\<[3]%
\>[3]{}\Conid{Cons}\;(\Varid{df}\;\Varid{x}\;\Varid{dx})\;(\Varid{dmap}\;\Varid{f}\;\Varid{df}\;\Varid{xs}\;\Varid{dxs}){}\<[E]%
\\
\>[B]{}\mbox{\onelinecomment  Other cases deal with invalid changes.}{}\<[E]%
\\
\>[B]{}\Varid{dmap}\;\Varid{f}\;\Varid{df}\;\Varid{xs}\;\Varid{dxs}\mathrel{=}\Conid{Nil}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{example}

However, derivative \ensuremath{\Varid{dmap}} is not asymptotically faster than \ensuremath{\Varid{map}}, and this is typical:
Derivatives of recursive functions
produced using this rule are often not asymptotically faster,
even when we consider less trivial change structures.
Deriving \ensuremath{\mathbf{letrec}\;\Varid{x}\mathrel{=}\Varid{t}_{1}\;\mathbf{in}\;\Varid{t}_{2}} can still be useful if \ensuremath{\Derive{\Varid{t}_{1}}}
and/or \ensuremath{\Derive{\Varid{t}_{2}}} is faster than its base term, but during our work we focus
mostly on using structural recursion. Alternatively, in \cref{ch:diff-examples}
and \cref{sec:plugin-design} we have shown how to incrementalize functions
(including recursive ones) using equational reasoning.

In general, when we invoke \ensuremath{\Varid{dmap}} on a change \ensuremath{\Varid{dxs}} from \ensuremath{\Varid{xs}_{1}} to \ensuremath{\Varid{xs}_{2}}, it is
important that \ensuremath{\Varid{xs}_{1}} and \ensuremath{\Varid{xs}_{2}} are similar enough that enough computation can be
reused. Say that \ensuremath{\Varid{xs}_{1}\mathrel{=}\Conid{Cons}\;\mathrm{2}\;(\Conid{Cons}\;\mathrm{3}\;(\Conid{Cons}\;\mathrm{4}}\linebreak\ensuremath{\Conid{Nil}))} and \ensuremath{\Varid{xs}_{2}\mathrel{=}\Conid{Cons}\;\mathrm{1}\;(\Conid{Cons}\;\mathrm{2}\;(\Conid{Cons}\;\mathrm{3}\;(\Conid{Cons}\;\mathrm{4}\;\Conid{Nil})))}: in this case, a change modifying each element of \ensuremath{\Varid{xs}_{1}},
and then replacing \ensuremath{\Conid{Nil}} by \ensuremath{\Conid{Cons}\;\mathrm{4}\;\Conid{Nil}}, would be inefficient to process, and
naive incrementalization would produce this scenario. In this case, it is clear
that a preferable change should simply insert \ensuremath{\mathrm{1}} at the beginning of the list,
as illustrated in \cref{sec:incr-fold} (though we have omitted the
straightforward definition of \ensuremath{\Varid{dmap}} for such a change structure).
In approaches like self-adjusting computation, this is ensured by using
memoization. In our approach, instead, we rely on changes that are nil or small
to detect when a derivative can reuse input computation.

The same problem affects naive attempts to incrementalize, for instance, a
simple factorial function; we omit details. Because of these issues, we focus on
incrementalization of structurally recursive functions, and on incrementalizing
generally recursive primitives using equational reasoning.
We return to this issue in \cref{ch:incr-conclusion-futwork}.

\subsection{Justification}
Here, we justify informally the rule for differentiating recursive functions
using fixpoint operators.

Let's consider STLC extended with a family of standard fixpoint
combinators $\Varid{fix}_{\ensuremath{\tau}}\ensuremath{\typcolon(\tau\to \tau)\to \tau}$, with
\ensuremath{\mathbf{fix}}-reduction defined by equation \ensuremath{\mathbf{fix}\;\Varid{f}\to \Varid{f}\;(\mathbf{fix}\;\Varid{f})}; we
search for a definition of \ensuremath{\Derive{\mathbf{fix}\;\Varid{f}}}.

Using informal equational reasoning, if a correct definition of
\ensuremath{\Derive{\mathbf{fix}\;\Varid{f}}} exists, it must satisfy
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Derive{\mathbf{fix}\;\Varid{f}}\cong\mathbf{fix}\;(\Derive{\Varid{f}}\;(\mathbf{fix}\;\Varid{f})){}\<[E]%
\ColumnHook
\end{hscode}\resethooks

We can proceed as follows:
% We recall that the derivative of a closed term is its nil change.
\begin{equational}
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}c<{\hspost}@{}}%
\column{BE}{@{}l@{}}%
\column{4}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[4]{}\Derive{\mathbf{fix}\;\Varid{f}}{}\<[E]%
\\
\>[B]{}\mathrel{=}{}\<[BE]%
\>[4]{}\mbox{\commentbegin  imposing that \ensuremath{\Derive{\text{\textendash}}} respects \ensuremath{\mathbf{fix}}-reduction here  \commentend}{}\<[E]%
\\
\>[4]{}\Derive{\Varid{f}\;(\mathbf{fix}\;\Varid{f})}{}\<[E]%
\\
\>[B]{}\mathrel{=}{}\<[BE]%
\>[4]{}\mbox{\commentbegin  using rules for \ensuremath{\Derive{\text{\textendash}}} on application  \commentend}{}\<[E]%
\\
\>[4]{}\Derive{\Varid{f}}\;(\mathbf{fix}\;\Varid{f})\;\Derive{\mathbf{fix}\;\Varid{f}}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
\end{equational}

This is a recursive equation in \ensuremath{\Derive{\mathbf{fix}\;\Varid{f}}}, so we can try
to solve it using \ensuremath{\mathbf{fix}} itself:
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Derive{\mathbf{fix}\;\Varid{f}}\mathrel{=}\mathbf{fix}\;(\lambda \Varid{dfixf}\to \Derive{\Varid{f}}\;(\mathbf{fix}\;\Varid{f})\;\Varid{dfixf}){}\<[E]%
\ColumnHook
\end{hscode}\resethooks

Indeed, this rule gives a correct derivative.
Formalizing our reasoning using denotational semantics would presumably require
the use of domain theory.
Instead, we prove correct a variant of \ensuremath{\mathbf{fix}} in \cref{ch:bsos}, but using
operational semantics and step-indexed logical relations.

% In particular
% \begin{code}
%    derive (fix (\ff -> t))
% =
%    fix (\dff -> (derive (\ff -> t) (fix (\ff -> t)) dff))
% =
%    fix (\dff -> derive t [ff := fix (\ff -> t)])
% \end{code}

% % |let ffact = fix (\ffact n -> n * ffact (n - 1)) in t2 =
% % letrec ffact = \n -> n * ffact (n - 1) in t2|
% % |
% % This rule is equivalent

% We can also derive the rule for |letrec|, based on this rewrite rule:
% |let ff = fix (\ff -> t) in t2 = letrec ff = t in t2|.
% We proceed as follows:
% \begin{equational}
% \begin{code}
%    derive(letrec ff = t in t2)
% =  {- -}
%    derive(lett ff = fix (\ff -> t) in t2)
% =  {- deriving |let| -}
%    let
%      ff   = fix (\ff -> t)
%      dff  = derive (fix (\ff -> t))
%    in derive t2
% =  {- deriving |fix| -}
%    let
%      ff   = fix (\ff -> t)
%      dff  = fix (\dff -> derive t [ff := (fix (\ff -> t))])
%    in derive t2
% =  {- deinline binding of |ff| -}
%    let
%      ff   = fix (\ff -> t)
%      dff  = fix (\dff -> derive t)
%    in derive t2
% =  {- |let| to |letrec| -}
%    letrec
%      ff   = t
%    in let
%      dff  = fix (\dff -> derive t)
%    in derive t2
% =  {- |let| to |letrec| -}
%    letrec
%      ff   = t
%      dff  = derive t
%    in derive t2
% \end{code}
% \end{equational}

\section{Completely invalid changes}
\label{sec:very-invalid}
\pg{Not sure that the reference to sec;invalid should go here. Ok, probably not.}
In some change sets, some changes might not be valid relative to
any source. In particular, we can construct examples in \ensuremath{\Delta (\mathbb{Z}\to \mathbb{Z})}.

To understand why this is plausible, we recall that as described
in \cref{ssec:pointwise-changes}, \ensuremath{\Varid{df}} can be decomposed into a
derivative, and a pointwise function change that is independent
of \ensuremath{\Varid{da}}. While pointwise changes can be defined arbitrarily, the
behavior of the derivative of \ensuremath{\Varid{f}} on changes is determined by the
behavior of \ensuremath{\Varid{f}}.

\begin{example}
  We search for a function change \ensuremath{\Varid{df}\typcolon\Delta (\mathbb{Z}\to \mathbb{Z})} such
that there exist no \ensuremath{\Varid{f}_{1},\Varid{f}_{2}\typcolon\mathbb{Z}\to \mathbb{Z}} for which
\ensuremath{\validfromto{\mathbb{Z}\to \mathbb{Z}}{\Varid{f}_{1}}{\Varid{df}}{\Varid{f}_{2}}}. To find \ensuremath{\Varid{df}}, we assume that there are \ensuremath{\Varid{f}_{1},\Varid{f}_{2}} such that \ensuremath{\validfromto{\mathbb{Z}\to \mathbb{Z}}{\Varid{f}_{1}}{\Varid{df}}{\Varid{f}_{2}}}, prove a few consequences, and construct
\ensuremath{\Varid{df}} that cannot satisfy them. Alternatively, we could pick the
desired definition for \ensuremath{\Varid{df}} right away, and prove by
contradiction that there exist no \ensuremath{\Varid{f}_{1},\Varid{f}_{2}} such that \ensuremath{\validfromto{\mathbb{Z}\to \mathbb{Z}}{\Varid{f}_{1}}{\Varid{df}}{\Varid{f}_{2}}}.

Recall that on integers \ensuremath{\Varid{a}_{1}\oplus \Varid{da}\mathrel{=}\Varid{a}_{1}\mathbin{+}\Varid{da}}, and that
\ensuremath{\validfromto{\mathbb{Z}}{\Varid{a}_{1}}{\Varid{da}}{\Varid{a}_{2}}} means \ensuremath{\Varid{a}_{2}\mathrel{=}\Varid{a}_{1}\oplus \Varid{da}\mathrel{=}\Varid{a}_{1}\mathbin{+}\Varid{da}}.
So, for any numbers \ensuremath{\Varid{a}_{1},\Varid{da},\Varid{a}_{2}} such that \ensuremath{\Varid{a}_{1}\mathbin{+}\Varid{da}\mathrel{=}\Varid{a}_{2}}, validity of \ensuremath{\Varid{df}} implies that
\[\ensuremath{\Varid{f}_{2}\;(\Varid{a}_{1}\mathbin{+}\Varid{da})\mathrel{=}\Varid{f}_{1}\;\Varid{a}_{1}\mathbin{+}\Varid{df}\;\Varid{a}_{1}\;\Varid{da}}.\]

For any two numbers \ensuremath{\Varid{b}_{1},\Varid{db}} such that \ensuremath{\Varid{b}_{1}\mathbin{+}\Varid{db}\mathrel{=}\Varid{a}_{1}\mathbin{+}\Varid{da}},
we have that
\[\ensuremath{\Varid{f}_{1}\;\Varid{a}_{1}\mathbin{+}\Varid{df}\;\Varid{a}_{1}\;\Varid{da}\mathrel{=}\Varid{f}_{2}\;(\Varid{a}_{1}\mathbin{+}\Varid{da})\mathrel{=}\Varid{f}_{2}\;(\Varid{b}_{1}\mathbin{+}\Varid{db})\mathrel{=}\Varid{f}_{1}\;\Varid{b}_{1}\mathbin{+}\Varid{df}\;\Varid{b}_{1}\;\Varid{db}}.\]

Rearranging terms, we have
\[\ensuremath{\Varid{df}\;\Varid{a}_{1}\;\Varid{da}\mathbin{-}\Varid{df}\;\Varid{b}_{1}\;\Varid{db}\mathrel{=}\Varid{f}_{1}\;\Varid{b}_{1}\mathbin{-}\Varid{f}_{1}\;\Varid{a}_{1}},\]
that is, \ensuremath{\Varid{df}\;\Varid{a}_{1}\;\Varid{da}\mathbin{-}\Varid{df}\;\Varid{b}_{1}\;\Varid{db}} does not depend on \ensuremath{\Varid{da}} and \ensuremath{\Varid{db}}.

For concreteness, let us fix \ensuremath{\Varid{a}_{1}\mathrel{=}\mathrm{0}}, \ensuremath{\Varid{b}_{1}\mathrel{=}\mathrm{1}}, and \ensuremath{\Varid{a}_{1}\mathbin{+}\Varid{da}\mathrel{=}\Varid{b}_{1}\mathbin{+}\Varid{db}\mathrel{=}\Varid{s}}. We have then that
\[\ensuremath{\Varid{df}\;\mathrm{0}\;\Varid{s}\mathbin{-}\Varid{df}\;\mathrm{1}\;(\Varid{s}\mathbin{-}\mathrm{1})\mathrel{=}\Varid{f}_{1}\;\mathrm{1}\mathbin{-}\Varid{f}_{1}\;\mathrm{0}},\]
Once we set \ensuremath{\Varid{h}\mathrel{=}\Varid{f}_{1}\;\mathrm{1}\mathbin{-}\Varid{f}_{1}\;\mathrm{0}}, we have \ensuremath{\Varid{df}\;\mathrm{0}\;\Varid{s}\mathbin{-}\Varid{df}\;\mathrm{1}\;(\Varid{s}\mathbin{-}\mathrm{1})\mathrel{=}\Varid{h}}.
Because \ensuremath{\Varid{s}} is just the sum of two arbitrary numbers, while \ensuremath{\Varid{h}}
only depends on \ensuremath{\Varid{f}_{1}}, this equation must hold for a fixed \ensuremath{\Varid{h}} and
for all integers \ensuremath{\Varid{s}}.

To sum up, we assumed for a given \ensuremath{\Varid{df}} there exists \ensuremath{\Varid{f}_{1},\Varid{f}_{2}} such
that \ensuremath{\validfromto{\mathbb{Z}\to \mathbb{Z}}{\Varid{f}_{1}}{\Varid{df}}{\Varid{f}_{2}}}, and concluded that there
exists \ensuremath{\Varid{h}\mathrel{=}\Varid{f}_{1}\;\mathrm{1}\mathbin{-}\Varid{f}_{1}\;\mathrm{0}} such that for all \ensuremath{\Varid{s}}
\[\ensuremath{\Varid{df}\;\mathrm{0}\;\Varid{s}\mathbin{-}\Varid{df}\;\mathrm{1}\;(\Varid{s}\mathbin{-}\mathrm{1})\mathrel{=}\Varid{h}}.\]

At this point, we can try concrete families of functions \ensuremath{\Varid{df}} to
obtain a contradiction. Substituting a linear polynomial $\ensuremath{\Varid{df}\;\Varid{a}\;\Varid{da}} = c_1 \cdot a + c_2 \cdot \ensuremath{\Varid{da}}$ fails to obtain a
contradiction: in fact, we can construct various \ensuremath{\Varid{f}_{1},\Varid{f}_{2}} such
that \ensuremath{\validfromto{\mathbb{Z}\to \mathbb{Z}}{\Varid{f}_{1}}{\Varid{df}}{\Varid{f}_{2}}}. So we try quadratic
polynomials: Substituting $\ensuremath{\Varid{df}\;\Varid{a}\;\Varid{da}} = c \cdot \ensuremath{\Varid{da}}^2$ succeeds:
we have that there is \ensuremath{\Varid{h}} such that for all integers \ensuremath{\Varid{s}}
\[c \cdot \left(s^2 - (s - 1)^2\right) = h.\]

However, $c \cdot \left(s^2 - (s - 1)^2\right) = 2 \cdot c \cdot
s - c$ which isn't constant, so there can be no such \ensuremath{\Varid{h}}.
\end{example}

\section{Pointwise function changes}
\label{ssec:pointwise-changes}
% We can also describe the difference from function |f| to function
% |f `oplus` df| as |nabla^f = \x -> f2 x `ominus` f1 x|.
\pg{Our definition of function change might seem to defy intuitions. In
  particular, pointwise changes might appear more intuitive. We discuss them
  later, too.}

We can also decompose function changes into orthogonal (and
possibly easier to understand) concepts.

Consider two functions \ensuremath{\Varid{f}_{1},\Varid{f}_{2}\typcolon\Conid{A}\to \Conid{B}} and two inputs \ensuremath{\Varid{a}_{1},\Varid{a}_{2}\typcolon\Conid{A}}.
The difference between \ensuremath{\Varid{f}_{2}\;\Varid{a}_{2}} and \ensuremath{\Varid{f}_{1}\;\Varid{a}_{1}} is due to changes to
both the function and its argument. We can compute the whole
change at once via a function change \ensuremath{\Varid{df}} as \ensuremath{\Varid{df}\;\Varid{a}_{1}\;\Varid{da}}. Or we
can compute separately the effects of the function change and of
the argument change. We can account for changes from \ensuremath{\Varid{f}_{1}\;\Varid{a}_{1}} to \ensuremath{\Varid{f}_{2}\;\Varid{a}_{2}}
using \ensuremath{f_{1}\myquote}, a derivative of \ensuremath{\Varid{f}_{1}}: \ensuremath{f_{1}\myquote\;\Varid{a}_{1}\;\Varid{da}\mathrel{=}\Varid{f}_{1}\;\Varid{a}_{2}\ominus \Varid{f}_{1}\;\Varid{a}_{2}\mathrel{=}\Varid{f}_{1}\;(\Varid{a}_{1}\oplus \Varid{da})\ominus \Varid{f}\;\Varid{a}_{1}}.%
%
\footnote{For simplicity, we use equality on changes, even though equality is
  too restrictive. Later (in \cref{sec:change-equivalence}) we'll define an
  equivalence relation on changes, called change equivalence and written
  \ensuremath{\Doe}, and use it systematically to relate changes in place of equality. For
  instance, we'll write that \ensuremath{f_{1}\myquote\;\Varid{a}_{1}\;\Varid{da}\Doe\Varid{f}_{1}\;(\Varid{a}_{1}\oplus \Varid{da})\ominus \Varid{f}_{1}\;\Varid{a}_{1}}.
  But for the present discussion, equality will do.}

We can account for changes from \ensuremath{\Varid{f}_{1}} to \ensuremath{\Varid{f}_{2}} using the
\emph{pointwise difference} of two functions, \ensuremath{\nabla \Varid{f}_{1}\mathrel{=}\lambda (\Varid{a}\typcolon\Conid{A})\to \Varid{f}_{2}\;\Varid{a}\ominus \Varid{f}_{1}\;\Varid{a}}; in particular, \ensuremath{\Varid{f}_{2}\;(\Varid{a}_{1}\oplus \Varid{da})\ominus \Varid{f}_{1}\;(\Varid{a}_{1}\oplus \Varid{da})\mathrel{=}\nabla \Varid{f}\;(\Varid{a}_{1}\oplus \Varid{da})}. Hence, a
function change simply \emph{combines} a derivative with a
pointwise change using change composition:
%
%To account for changes to $a$, we can use
%$f'$, the derivative of $f$. To account for changes to $f$, we
%can use the \emph{pointwise difference} of two functions, $\nabla
%f = \Lam{a}{\App{\New{f}}{a} \DIFF \App{\Old{f}}{a}}$.
%
% Now,
%assuming for the moment the incrementalization theorem, we can
%show the meaning of a function change $df$ in terms of
%derivatives and pointwise changes:
%
\begin{equation}
\begin{aligned}
\label{eq:pointwise-rewrite}
\ensuremath{\Varid{df}\;\Varid{a}_{1}\;\Varid{da}} & = \ensuremath{\Varid{f}_{2}\;\Varid{a}_{2}\ominus \Varid{f}_{1}\;\Varid{a}_{1}}\\
           & = \ensuremath{(\Varid{f}_{1}\;\Varid{a}_{2}\ominus \Varid{f}_{1}\;\Varid{a}_{1})\circledcirc(\Varid{f}_{2}\;\Varid{a}_{2}\ominus \Varid{f}_{1}\;\Varid{a}_{2})}\\
           & = \ensuremath{f_{1}\myquote\;\Varid{a}_{1}\;\Varid{da}\circledcirc\nabla \Varid{f}\;(\Varid{a}_{1}\oplus \Varid{da})}
\end{aligned}
\end{equation}
One can also compute a pointwise change from a function change:
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\nabla\;\Varid{f}\;\Varid{a}\mathrel{=}\Varid{df}\;\Varid{a}\;\NilC{\Varid{a}}{}\<[E]%
\ColumnHook
\end{hscode}\resethooks

While some might find pointwise changes a more natural concept,
we find it easier to use our definitions of function changes,
which combines both pointwise changes and derivatives into a
single concept.
Some related works explore the use of pointwise changes; we discuss them in
\cref{sec:rw-partial-differentials}.

\section{Modeling only valid changes}
\label{sec:alt-change-validity}
\newcommand{\ilcA}{ILC'14}
\newcommand{\ilcB}{ILC'17}

In this section, we contrast briefly the formalization of ILC in this thesis (for short
\ilcB) with the one we used in our first formalization~\citep{CaiEtAl2014ILC}
(for short \ilcA). We keep the discussion somewhat informal; we have sketched
proofs of our claims and mechanized some, but we omit all proofs here.
We discuss both formalizations using our current notation and terminology,
except for concepts that are not present here.

Both formalizations model function changes semantically, but the two models we
present are different. Overall, \ilcB{} uses simpler machinery and seems easier
to extend to more general base languages, and its mechanization of \ilcB{}
appears simpler and smaller.
Instead, \ilcA{} studies additional entities but better behaved entities.

In \ilcB{}, input and output domains of function changes contain
\emph{invalid} changes, while in \ilcA{} these domains are restricted to valid
changes via dependent types; \ilcA{} also considers the denotation of \ensuremath{\Derive{\Varid{t}}},
whose domains include invalid changes, but such denotations are studied only indirectly.
In both cases, function changes must map valid
changes to valid changes. But \ilcA{}, application \ensuremath{\Varid{df}\;\Varid{v}_{1}\;\Varid{dv}} is only well-typed
is \ensuremath{\Varid{dv}} is a change valid from \ensuremath{\Varid{v}_{1}}, hence we can simply say that \ensuremath{\Varid{df}\;\Varid{v}_{1}} respects
change equivalence. As discussed in \cref{sec:change-equivalence}, in \ilcB{}
the analogous property has a trickier statement: we can write \ensuremath{\Varid{df}\;\Varid{v}_{1}} and apply
it to arbitrary equivalent changes \ensuremath{\Varid{dv}_{1}\Doe\Varid{dv}_{2}}, even if their source is not
\ensuremath{\Varid{v}_{1}}, but such change equivalences are not preserved.

We can relate the two models by defining a logical relation called
\emph{erasure} (similar to the one described by \citeauthor{CaiEtAl2014ILC}): an
\ilcA{} function change \ensuremath{\Varid{df}} erases to an \ilcB{} function change \ensuremath{\Varid{df'}} relative
to source \ensuremath{\Varid{f}\typcolon\Conid{A}\to \Conid{B}} if, given any change \ensuremath{\Varid{da}} that erases
to \ensuremath{\Varid{da'}} relative to source \ensuremath{\Varid{a}_{1}\typcolon\Conid{A}}, output change \ensuremath{\Varid{df}\;\Varid{a}_{1}\;\Varid{da}} erases to \ensuremath{\Varid{df'}\;\Varid{a}_{1}\;\Varid{da'}} relative to source \ensuremath{\Varid{f}\;\Varid{a}_{1}}.
For base types, erasure simply connects corresponding \ensuremath{\Varid{da}} (with source) with
\ensuremath{\Varid{da'}} in a manner dependent from the base type (often, just throwing away any
embedded proofs of validity).
In all cases, one can show that if and only if \ensuremath{\Varid{dv}} erases to \ensuremath{\Varid{dv'}} with source
\ensuremath{\Varid{v}_{1}}, then \ensuremath{\Varid{v}_{1}\oplus \Varid{dv}\mathrel{=}\Varid{v}_{2}\oplus \Varid{dv'}} (for suitable variants of \ensuremath{\oplus }):
in other words, \ensuremath{\Varid{dv}} and \ensuremath{\Varid{dv'}} share source and destination (technically,
\ilcB{} changes have no fixed source, so we say that they are changes from \ensuremath{\Varid{v}_{1}}
to \ensuremath{\Varid{v}_{2}} for some \ensuremath{\Varid{v}_{2}}).

In \ilcA{} there is a different incremental semantics \ensuremath{\EvalInc{\Varid{t}}} for terms \ensuremath{\Varid{t}},
but it is still a valid \ilcA{} change. One can show that \ensuremath{\EvalInc{\Varid{t}}} (as
defined in \ilcA{}) erases to \ensuremath{\EvalInc{\Derive{\Varid{t}}}} (as defined in \ilcB{}) relative to
source \ensuremath{\Eval{\Varid{t}}}; in fact, the needed proof is sketched by
\citeauthor{CaiEtAl2014ILC}, through in disguise.

It seems clear there is no isomorphism between \ilcA{} changes and \ilcB{} changes.
An \ilcB{} function change also accepts invalid changes, and the behavior on
those changes can't be preserved by an isomorphism.
Worse, it seems hard to define a non-isomorphic mapping:
to map an \ilcA{} change \ensuremath{\Varid{df}} to an an \ilcB{} change \ensuremath{\Varid{erase}\;\Varid{df}}, we have to
define behavior for \ensuremath{(\Varid{erase}\;\Varid{df})\;\Varid{a}\;\Varid{da}} even when \ensuremath{\Varid{da}} is invalid.
As long as we work in a constructive setting,
we cannot decide whether \ensuremath{\Varid{da}} is valid in general, because \ensuremath{\Varid{da}} can be a
function change with infinite domain.

We can give however a definition that does not need to detect such invalid
changes: Just extract source and destination from a function change using valid
change \ensuremath{\NilC{\Varid{v}}}, and take difference of source and destination using \ensuremath{\ominus }
in the target system.
\begin{hscode}\SaveRestoreHook
\column{B}{@{}>{\hspre}l<{\hspost}@{}}%
\column{3}{@{}>{\hspre}l<{\hspost}@{}}%
\column{E}{@{}>{\hspre}l<{\hspost}@{}}%
\>[3]{}\Varid{unerase}\;(\sigma\to \tau)\;\Varid{df'}\mathrel{=}\mathbf{let}\;\Varid{f}\mathrel{=}\lambda \Varid{v}\to \Varid{df'}\;\Varid{v}\;\NilC{\Varid{v}}\;\mathbf{in}\;(\Varid{f}\oplus \Varid{df'})\ominus \Varid{f}{}\<[E]%
\\
\>[3]{}\Varid{unerase}\;\text{\textunderscore}\;\Varid{dv'}\mathrel{=}\ldots{}\<[E]%
\\[\blanklineskip]%
\>[3]{}\Varid{erase}\;(\sigma\to \tau)\;\Varid{df}\mathrel{=}\mathbf{let}\;\Varid{f}\mathrel{=}\lambda \Varid{v}\to \Varid{df}\;\Varid{v}\;\NilC{\Varid{v}}\;\mathbf{in}\;(\Varid{f}\oplus \Varid{df})\ominus \Varid{f}{}\<[E]%
\\
\>[3]{}\Varid{erase}\;\text{\textunderscore}\;\Varid{dv}\mathrel{=}\ldots{}\<[E]%
\ColumnHook
\end{hscode}\resethooks
We define these function by induction on types (for elements of \ensuremath{\Delta \tau}, not
arbitrary change structures), and we overload \ensuremath{\ominus } for \ilcA{} and
\ilcB{}.
We conjecture that for all types \ensuremath{\tau} and for all \ilcB{} changes \ensuremath{\Varid{dv'}} (of the
right type),
\ensuremath{\Varid{unerase}\;\tau\;\Varid{dv'}} erases to \ensuremath{\Varid{dv'}}, and for all \ilcA{} changes \ensuremath{\Varid{dv}}, \ensuremath{\Varid{dv}} erases
to \ensuremath{\Varid{erase}\;\tau\;\Varid{dv'}}.

Erasure is a well-behaved logical relation, similar to the ones relating source
and destination language of a compiler and to partial equivalence relations. In
particular, it also induces partial equivalence relations (PER) (see
\cref{sec:doe-per}), both on \ilcA{} changes and on \ilcB{} changes: two \ilcA{}
changes are equivalent if they erase to the same \ilcB{} change, and two \ilcB{}
changes are equivalent if the same \ilcA{} change erases to both. Both relations
are partial equivalence relations (and total on valid changes). Because changes
that erase to each other share source and destination, these induced
equivalences coincide again with change equivalence. That both relations are
PERs also means that erasure is a so-called \emph{quasi-PER}~\citep{Krishnaswami2013internalizing}.
Quasi-PERs are a natural (though not obvious) generalization of PERs for
relations among different sets $R \subseteq S_1 \times S_2$: such relations cannot
be either symmetric or transitive. However, we make no use of additional
properties of quasi-PERs, hence we don't discuss them in further detail.

\subsection{One-sided vs two-sided validity}
There are also further superficial differences among the two definitions.
In \ilcA{}, changes valid with soure \ensuremath{\Varid{a}} have dependent type \ensuremath{\Delta \Varid{a}}. This
dependent type is indexed by the source but not by the destination. Dependent
function changes with source \ensuremath{\Varid{f}\typcolon\Conid{A}\to \Conid{B}} have type \ensuremath{(\Varid{a}\typcolon\Conid{A})\to \Delta \Varid{a}\to \Delta (\Varid{f}\;\Varid{a})}, relating the behavior of function change \ensuremath{\Varid{df}} with the behavior of \ensuremath{\Varid{f}} on
original inputs. But this is half of function validity: to relate the behavior of \ensuremath{\Varid{df}}
with the behavior of \ensuremath{\Varid{df}} on updated inputs,
in \ilcA{} valid function changes have to satisfy an additional
equation called \emph{preservation of future}:\footnote{Name suggested by Yufei Cai.}
  \[\ensuremath{\Varid{f}_{1}\;\Varid{a}_{1}\oplus \Varid{df}\;\Varid{a}_{1}\;\Varid{da}\mathrel{=}(\Varid{f}_{1}\oplus \Varid{df})\;(\Varid{a}_{1}\oplus \Varid{da})}.\]
This equation appears inelegant, and mechanized proofs were often complicated by the
need to perform rewritings using it. Worse, to show that a function change is
valid, we have to use different approaches to prove it has the correct source
and the correct destination.

This difference is however superficial.
If we replace \ensuremath{\Varid{f}_{1}\oplus \Varid{df}} with \ensuremath{\Varid{f}_{2}} and \ensuremath{\Varid{a}_{1}\oplus \Varid{da}} with \ensuremath{\Varid{a}_{2}}, this
equation becomes \ensuremath{\Varid{f}_{1}\;\Varid{a}_{1}\oplus \Varid{df}\;\Varid{a}_{1}\;\Varid{da}\mathrel{=}\Varid{f}_{2}\;\Varid{a}_{2}}, a consequence of \ensuremath{\validfromto{\Varid{f}_{1}}{\Varid{df}}{\Varid{f}_{2}}{\text{\textendash}}}. So one might suspect that \ilcB{} valid function changes also satisfy this
equation. This is indeed the case:

% This equation is one requirement that old-style function changes
% had to satisfy. What we have seen is that the new-style
% definition of validity, although different (and we believe
% simpler), implies the same equation.
% First, we show that our valid function changes satisfy
\begin{lemma}
  A valid function change \ensuremath{\validfromto{\Conid{A}\to \Conid{B}}{\Varid{f}_{1}}{\Varid{df}}{\Varid{f}_{2}}} satisfies equation
  \[\ensuremath{\Varid{f}_{1}\;\Varid{a}_{1}\oplus \Varid{df}\;\Varid{a}_{1}\;\Varid{da}\mathrel{=}(\Varid{f}_{1}\oplus \Varid{df})\;(\Varid{a}_{1}\oplus \Varid{da})}\]
  on any valid input \ensuremath{\validfromto{\Conid{A}\to \Conid{B}}{\Varid{a}_{1}}{\Varid{da}}{\Varid{a}_{2}}}.
\end{lemma}
% \begin{proof}
% Assume |fromto (A -> B) f1 df f2| and |fromto A a1 da
% a2|.
% We have to show |f1 a1 `oplus` df a1 da = (f1 `oplus` df) (a1 `oplus` da)|.

% From the hypotheses one can briefly show that |fromto B (f1 a1) (df a1 da) (f2
% a2)|, that |f2 = f1 `oplus` df| and that |a2 = a1 `oplus` da|.
% We have seen in \cref{eq:fun-preserv-eq} that |f2 a2 = f1 a1
% `oplus` df a1 da|.
% Combining these equations, it follows as desired that
% \begin{equational}
%   \begin{code}
%   f1 a1 `oplus` df a1 da
% =
%   f2 a2
% =
%   (f1 `oplus` df) (a1 `oplus` da)
%   \end{code}
% \end{equational}
% % \[
% %   |f1 a1 `oplus` df a1 da = (f1 `oplus` df) (a1 `oplus` da) = f1
% %   (a1 `oplus` da) `oplus` df (a1 `oplus` da) (nil (a1 `oplus`
% %   da))|.\]
% \end{proof}

Conversely, one can also show that \ilcA{} function changes also satisfy
two-sided validity as defined in \ilcB{}. Hence, the only true difference
between \ilcA{} and \ilcB{} models is the one we discussed earlier, namely
whether function changes can be applied to invalid inputs or not.

We believe it could be possible to formalize the \ilcA{} model using two-sided
validity, by defining a dependent type of valid changes:
\ensuremath{\Delta_2\;(\Conid{A}\to \Conid{B})\;\Varid{f}_{1}\;\Varid{f}_{2}\mathrel{=}(\Varid{a}_{1}\;\Varid{a}_{2}\typcolon\Conid{A})\to \Delta_2\;\Conid{A}\;\Varid{a}_{1}\;\Varid{a}_{2}\to \Delta_2\;\Conid{B}\;(\Varid{f}_{1}\;\Varid{a}_{1})\;(\Varid{f}_{2}\;\Varid{a}_{2})}.
We provide more details on such a transformation in
\cref{ch:diff-parametricity-system-f}.

Models restricted to valid changes (like \ilcA{}) are related to models based on
directed graphs and reflexive graphs, where values are graphs vertexes, changes
are edges between change source and change destination (as hinted earlier). In
graph language, validity preservation means that function changes are graph
homomorphisms.

Based on similar insights, \citet{Atkey2015ILC} suggests modeling ILC using
reflexive graphs, which have been used to construct parametric models for System
F and extensions, and calls for research on the relation between ILC and
parametricity. As follow-up work, \citet{CaiPhD} studies models of ILC based on
directed and reflexive graphs.

% Because of |fromto (Int -> Int) f1 df f2| and because |`oplus`|
% respects validity we can show that, for any valid input |fromto
% Int a1 da a2|, we have
% \begin{equation}
%   \label{eq:ex-invalid-int-int}
%   |f2 a2 = f1 a1 `oplus` df a1 da|.
% \end{equation}

% Recall that on integers |a1 `oplus` da = a1 + da|, and that
% |fromto Int a1 da a2| means |a2 = a1 `oplus` da = a1 + da|. So
% \cref{eq:ex-invalid-int-int} becomes
% \begin{equation}
%   %\label{eq:ex-invalid-int-int}
%   |f2 (a1 + da) = f1 a1 + df a1 da|.
% \end{equation}
