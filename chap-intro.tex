\chapter{Introduction}

Many program perform queries on collections of data, and for non-trivial amounts
of data it is useful to execute the queries efficiently. When the data is
updated often enough, it can also be useful to update the results of some
queries \emph{incrementally} whenever the input changes, so that up-to-date
results are quickly available, even for queries that are expensive to execute.

For instance, a program manipulating anagraphic data about citizens of a country
might need to compute statistics on them, such as their average age, and update
those statistics when the set of citizens changes.

Traditional relational database management systems (RDBMS) support both queries
optimization and (in quite a few cases) incremental update of query results
(called there \emph{incremental view maintenance}).

However, often queries are executed on collections of data that are not stored
in a database, but in collections manipulated by some program. Moving in-memory
data to RDBMSs typically does not improve
performance~\citep{Stonebraker07,Rompf2015functional}, and reusing database
optimizers is not trivial.

Moreover, many programming languages are far more expressive than RDBMSs.
Typical RDBMS can only manipulate SQL relations, that is multisets (or bags) of
tuples (or sometimes sets of tuples, after duplicate elimination). Typical
programming languages (PL) support also arbitrarily nested lists and maps of
data, and allow programmers to define new data types with few restrictions; a
typical PL will also allow a far richer set of operations than SQL.

However, typical PL do not apply typical database optimizations to collection
queries, and if queries are incrementalized, this is often done by hand, even
though code implementing incremental query is error-prone and
hard-to-maintain~\citep{Salvaneschi13reactive}.

What's worse, some of these manual optimizations are best done over the whole
program. For instance, adding an index on some collection can speed up looking
for some information, but each index must be maintained incrementally when the
underlying data changes. Depending on the actual queries and updates performed
on the collection, and on how often they happen, it might turn out that updating
an index takes more time than the index saves; hence the choice of which indexes
to enable depends on the whole program. However, adding/removing an index
requires updating all PL queries to use it, while RDBMS queries can use an index
transparently.

\section{This thesis}
To reduce the need for manual optimizations, in this thesis we propose
techniques for optimizing collection queries and executing them
incrementally.

We consider the problem for functional programming languages such as Haskell or
Scala, and we consider collection queries written using the APIs of their
collection libraries, which we treat as an embedded domain-specific language (EDSL). Such
APIs (or DSLs) contain powerful operators on collections such as $\Varid{map}$,\pg{exemplify or take for granted?}
which are higher-order, that
is they take as arguments arbitrary functions in the host language that we must
also handle.

Therefore, our optimizations and incrementalizations must handle programs in
higher-order EDSLs that can contain arbitrary code in the host language. Hence,
many of our optimizations will exploit on properties of our collection EDSL, but
will need to handle host language code. We restrict the problem to purely
functional programs (without mutation or other side effects, mostly including
non-termination), because such programs can be more ``declarative'' and because
avoiding side effects can enable more powerful optimization and simplify the
work of the optimizer at the same time.

This thesis is divided into three parts:
\begin{itemize}
\item In \cref{part:ch-aosd13}, we describe work on optimizing collection queries by static program transformation~\citep{GiarrussoAOSD13}.
\item In \cref{part:incr}, we describe work on incrementalizing programs
  by static program transformation. This thesis presents the first approach that
  handles higher-order programs by using program transformation; hence, while
  our main examples use collection queries, we phrase the work in terms of
  $\lambda$-calculi with unspecified primitives~\citep*{CaiEtAl2014ILC}.
\item In \cref{part:caching}, we extend ILC with a further program transformation
  step, so that base programs can store intermediate results and derivatives can
  reuse them, but without resorting to dynamic memoization and necessarily
  needing to look results up at runtime. To this end, we build on work by
\citet{Liu00} and extend it to a higher-order, typed setting.
\end{itemize}

\Cref{part:incr} and \cref{part:caching} are more theoretical than
\cref{part:ch-aosd13}. That was necessary, because optimizations in
\cref{part:ch-aosd13} are much better understood than our approach to
incrementalization.

To incrementalize programs, we are the first to extend to higher-order programs
techniques based on finite differencing for queries on
collections~\citep{Paige82FDC} and
databases~\citep{Blakeley:1986:EUM,Gupta99MMV}.
Incrementalizing by finite differencing is a well-understood technique for
database queries. How to generalize it for higher-order programs or beyond
databases was less clear, so we spend significant energy on providing sound
mathematical foundations for this transformation.

In fact, it took us a while to be sure that our transformation was correct, and
to understand why; our first correctness proof~\citep*{CaiEtAl2014ILC}, while a
significant step, was still more complex than needed. In \cref{part:incr},
especially \cref{ch:derive-formally}, we offer a mathematically much simpler
proof.

\Cref{part:incr} makes the following contributions:
\begin{itemize}
\item We present a novel mathematical theory of changes and derivatives, which
  is more general than other work in the field because changes are first-class
  entities, they are distinct from base values and they are defined also for
  functions.
  %(\cref{sec:1st-order-changes}).
  %KO: I think the next sentence cannot be understood at this point.
  %We introduce changes for complex types, defined compositionally.
%
\item We present the first approach to incremental computation for pure
  $\lambda$-calculi by a source-to-source transformation, $\DERIVE$, that
  requires no run-time support. The transformation produces an incremental
  program in the same language; all optimization techniques for the original
  program are applicable to the incremental program as well.
%KO: commented this out. I think the purity is not important enough
%to deserve another sentence here, since we only vaguely hint
%at "further research".
%Since our incremental programs use no impure features, they are
%especially amenable to further optimizations, making this approach
%very suitable for further research.
%
% KO: Let's have one bullet point per section. Also, a conjecture
% sounds like a rather weak contribution
%\item We argue that incrementalization is efficient on
%  \emph{self-maintainable programs}, and discuss how further research on
%  static or dynamic memoization can speed up a larger class of programs (\cref{sec:performance-cons}).
%  \pg{This contribution references text which is now commented
%    out. I believe the text should be brought back in.}
%
\item We prove that our incrementalizing transformation $\DERIVE$
is correct~(\cref{eq:correctness}) by a novel machine-checked logical relation
proof, mechanized in Agda~\citep{agda-head}.

\item While we focus mainly on the theory of changes
and derivatives, we also perform a performance case study.
We implement the derivation transformation in Scala,
with a plug-in architecture that can be extended with new base
types and primitives. We define a plugin with support for
different collection types and use the plugin to
incrementalize a variant of the MapReduce programming model~\citep{Lammel07}.
  Benchmarks show that on this program,
  incrementalization can reduce asymptotic complexity and can turn $O(n)$
  performance into $O(1)$, improving running time by over 4
  orders of magnitude on realistic inputs (\cref{sec:applying}).
\end{itemize}

\pg{Describe \cref{part:caching}}
\subsection{Included papers}
This thesis includes material from joint work with colleagues.

\Cref{part:ch-aosd13} is based on work by \citet*{GiarrussoAOSD13}. While the
work was in collaboration, a few clearer responsibilities arose.
I did most of the implementation work, and collaborated to the writing: among
other things I devised the embedding for collection operations, implemented
optimizations and indexing, implemented compilation when interpretation did not
achieve sufficient performance, and performed the performance evaluation.
Michael Eichberg and Ralf Mitschke contributed to the evaluation by adapting
FindBugs queries.
Christian K{\"{a}}stner contributed, among other things, to the experiment
design for the performance evaluation. Klaus Ostermann proposed the original
idea (together with an initial prototype) and supervised the project.

\Cref{part:incr} is originally based on work by \citet*{CaiEtAl2014ILC}, though
significantly revised. This work was even more of a team effort. I designed the
overall project and came up with the original notion of change structures; Cai
Yufei contributed differentiation itself and its first correctness proof.
\Cref{part:incr} contains novel correctness proof; its history and
contributions are discussed in \cref{sec:ilc-dev-history}.

Furthermore, \cref{part:caching} comes from a new, unpublished
manuscript~\citep*{Giarrusso2018Static}. I
designed the overall approach, the transformation and the case study on
sequences and nested loops. Proofs were done in collaboration with Yann
RÃ©gis-Gianas: most of the work is his, though I contributed significantly to the
correctness proof for ILC. Philipp Schuster contributed to the evaluation,
devising language plugins for bags and maps.

\pg{Readd section on excluded papers.}
% \subsection{Excluded papers}
% During my PhD work I collaborated on several other papers.

% \paragraph{Software Product Lines}
% Initial work on Software Product Lines lead to \cite{KPO:VaMoS11} and
% \cite{KGREOB:OOPSLA11}. On the same line I collaborated to experiments in
% \cite{SRKGAK:SPLC11} and its updated version\pg{TODO}.
% % \pg{Cite work on VarPL? Unlikely.}

% \paragraph{Modularity}
% \cite{OGKR:ECOOP11}

% \paragraph{DSL work}
% While working on modular embedded DSLs I collaborated to \citet{ErdwegGR12},
% \pg{TODO GADT paper}, \pg{TODO maybe manuscript on cake pattern?}.

% Modern libraries offer high-level APIs for manipulating (in-memory) collections;
% equivalently, such an API is an embedded domain-specific language (EDSL).

% Compared to SQL, EDSL queries will typically be able to use user-defined
% functions in queries. Moreover, the author of EDSL queries can enjoy abstraction
% mechanisms from the underlying language.

% \pg{Examples!}

% Collection operations are typically executed directly; however, they can instead
% construct a query representation that can then be optimized.

% \section{Our design for incrementalizing queries}
% We designed our incrementalization system by abstracting from needs and ideas for
% collection APIs.
% \begin{itemize}
% \item collection APIs are typically higher-order. This allows further
%   flexibility compared to first-order query languages: in particular we can
%   design new operators in terms of existing ones.
% \item many collection types support equations that can be used for optimization.
%   For instance
% \end{itemize}

% \subsection{Domain-specific}
% Special optimizations are possible because many collection datatypes, equality
% is not purely structural. Two lists are equal if they are structurally equal.
% But two sets are equal if they have the same elements, which does not imply they
% are structurally equal.\footnote{\pg{Cool but not necessarily appropriate here.}
%   Technically, the datatypes are not freely generated and their signatures
%   contain further equations.}
% %
% A general-purpose optimizer cannot exploit this to return a structurally
% different set with ``the same meaning'', but a domain-specific optimizer can be
% instructed to do so.

% Taking this into account we were led to design our incrementalization system to
% allow domain-specific support from the start.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "thesis-main"
%%% End:
